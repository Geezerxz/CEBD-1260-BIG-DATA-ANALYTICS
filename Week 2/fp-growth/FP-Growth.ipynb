{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FP-Growth Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical example from the MLlib website\n",
    "https://spark.apache.org/docs/latest/ml-frequent-pattern-mining.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+\n",
      "| id|       items|\n",
      "+---+------------+\n",
      "|  0|   [1, 2, 5]|\n",
      "|  1|[1, 2, 3, 5]|\n",
      "|  2|      [1, 2]|\n",
      "+---+------------+\n",
      "\n",
      "+---------+----+\n",
      "|    items|freq|\n",
      "+---------+----+\n",
      "|      [5]|   2|\n",
      "|   [5, 1]|   2|\n",
      "|[5, 1, 2]|   2|\n",
      "|   [5, 2]|   2|\n",
      "|      [2]|   3|\n",
      "|      [1]|   3|\n",
      "|   [1, 2]|   3|\n",
      "+---------+----+\n",
      "\n",
      "+----------+----------+------------------+\n",
      "|antecedent|consequent|        confidence|\n",
      "+----------+----------+------------------+\n",
      "|       [5]|       [1]|               1.0|\n",
      "|       [5]|       [2]|               1.0|\n",
      "|    [1, 2]|       [5]|0.6666666666666666|\n",
      "|    [5, 2]|       [1]|               1.0|\n",
      "|    [5, 1]|       [2]|               1.0|\n",
      "|       [2]|       [5]|0.6666666666666666|\n",
      "|       [2]|       [1]|               1.0|\n",
      "|       [1]|       [5]|0.6666666666666666|\n",
      "|       [1]|       [2]|               1.0|\n",
      "+----------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.fpm import FPGrowth\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (0, [1, 2, 5]),\n",
    "    (1, [1, 2, 3, 5]),\n",
    "    (2, [1, 2])\n",
    "], [\"id\", \"items\"])\n",
    "df.show()\n",
    "\n",
    "fpGrowth = FPGrowth(itemsCol=\"items\", minSupport=0.5, minConfidence=0.6)\n",
    "model = fpGrowth.fit(df)\n",
    "\n",
    "# Display frequent itemsets.\n",
    "model.freqItemsets.show()\n",
    "\n",
    "# Display generated association rules.\n",
    "model.associationRules.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## msnbc.com anonymous web data\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/msnbc-mld/msnbc.data.html\n",
    "\n",
    "This data describes the page visits of users who visited msnbc.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+\n",
      "| id|              items|\n",
      "+---+-------------------+\n",
      "|  7|                [1]|\n",
      "|  8|                [2]|\n",
      "|  9|          [3, 2, 4]|\n",
      "| 10|                [5]|\n",
      "| 11|                [1]|\n",
      "| 12|                [6]|\n",
      "| 13|                [1]|\n",
      "| 14|                [6]|\n",
      "| 15|          [8, 7, 6]|\n",
      "| 16|[10, 3, 5, 4, 6, 9]|\n",
      "| 17|            [1, 11]|\n",
      "| 18|               [12]|\n",
      "| 19|                [1]|\n",
      "| 20|                [8]|\n",
      "| 21|                [6]|\n",
      "| 22|                [2]|\n",
      "| 23|            [9, 12]|\n",
      "| 24|                [3]|\n",
      "| 25|                [9]|\n",
      "| 26|                [3]|\n",
      "+---+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the file and manipulate it to adapt to the Spark dataframe structure\n",
    "df = spark.read.text(\"msnbc990928.seq\").toPandas()\n",
    "df = df.iloc[7:,].reset_index().dropna()\n",
    "df.columns = ['id', 'items']\n",
    "df['items'] = df['items'].apply(lambda x: list(set(x.split())))\n",
    "spark_df = spark.createDataFrame(df)\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "* 1\tfrontpage \n",
    "* 2\tnews \n",
    "* 3\ttech \n",
    "* 4\tlocal \n",
    "* 5\topinion \n",
    "* 6\ton-air \n",
    "* 7\tmisc \n",
    "* 8\tweather \n",
    "* 9\tmsn-news \n",
    "* 10\thealth \n",
    "* 11\tliving \n",
    "* 12\tbusiness \n",
    "* 13\tmsn-sports \n",
    "* 14\tsports \n",
    "* 15\tsummary \n",
    "* 16\tbbs \n",
    "* 17\ttravel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|items  |freq  |\n",
      "+-------+------+\n",
      "|[1]    |313181|\n",
      "|[6]    |217101|\n",
      "|[2]    |175286|\n",
      "|[3]    |121948|\n",
      "|[4]    |121719|\n",
      "|[14]   |119138|\n",
      "|[12]   |112183|\n",
      "|[8]    |95615 |\n",
      "|[9]    |90192 |\n",
      "|[7]    |80514 |\n",
      "|[13]   |76948 |\n",
      "|[2, 1] |74704 |\n",
      "|[11]   |57597 |\n",
      "|[10]   |50606 |\n",
      "|[12, 1]|43178 |\n",
      "|[6, 1] |40078 |\n",
      "|[4, 1] |39183 |\n",
      "|[14, 1]|38826 |\n",
      "|[7, 1] |36419 |\n",
      "|[3, 1] |33364 |\n",
      "|[7, 6] |33283 |\n",
      "|[11, 1]|32722 |\n",
      "|[15]   |29200 |\n",
      "|[4, 2] |27533 |\n",
      "|[7, 4] |27029 |\n",
      "|[10, 1]|26248 |\n",
      "|[2, 6] |25425 |\n",
      "|[3, 2] |25292 |\n",
      "|[5]    |24987 |\n",
      "|[12, 2]|23453 |\n",
      "+-------+------+\n",
      "only showing top 30 rows\n",
      "\n",
      "+----------+----------+-------------------+\n",
      "|antecedent|consequent|confidence         |\n",
      "+----------+----------+-------------------+\n",
      "|[11, 2]   |[1]       |0.7542324081538638 |\n",
      "|[10, 2]   |[1]       |0.6829185520361991 |\n",
      "|[12, 2]   |[1]       |0.6619195838485482 |\n",
      "|[7, 2]    |[1]       |0.6501154734411085 |\n",
      "|[14, 2]   |[1]       |0.6325142375026366 |\n",
      "|[4, 2]    |[1]       |0.6016779864163004 |\n",
      "|[2, 6]    |[1]       |0.5941396263520158 |\n",
      "|[3, 2]    |[1]       |0.5813300648426379 |\n",
      "|[11]      |[1]       |0.5681198673542025 |\n",
      "|[7, 4]    |[1]       |0.54023456287691   |\n",
      "|[7, 2]    |[4]       |0.5211366603072598 |\n",
      "|[10]      |[1]       |0.5186736750582935 |\n",
      "|[5]       |[1]       |0.49405690959298837|\n",
      "|[15]      |[6]       |0.4806164383561644 |\n",
      "|[10, 1]   |[2]       |0.45999695214873515|\n",
      "|[7]       |[1]       |0.4523312715800979 |\n",
      "|[3, 1]    |[2]       |0.44068457019542023|\n",
      "|[2]       |[1]       |0.4261834944034321 |\n",
      "|[4, 1]    |[2]       |0.42278539162391854|\n",
      "|[7]       |[6]       |0.41338152371016224|\n",
      "|[7, 1]    |[4]       |0.4009445619045004 |\n",
      "|[11, 1]   |[2]       |0.4002811564085325 |\n",
      "|[12]      |[1]       |0.3848889760480643 |\n",
      "|[7, 4]    |[2]       |0.3840319656665063 |\n",
      "|[4, 2]    |[7]       |0.37700214288308576|\n",
      "|[6, 1]    |[2]       |0.37691501571934727|\n",
      "|[4, 1]    |[7]       |0.3726616134548146 |\n",
      "|[12, 1]   |[2]       |0.3595349483533281 |\n",
      "|[7, 1]    |[2]       |0.3555561657376644 |\n",
      "|[10]      |[2]       |0.34936568786309924|\n",
      "+----------+----------+-------------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define values for minSupport and minConfidence\n",
    "\n",
    "# Fit the model\n",
    "fpGrowth = FPGrowth(itemsCol=\"items\", minSupport=0.01, minConfidence=0.005)\n",
    "model = fpGrowth.fit(spark_df)\n",
    "\n",
    "# Display frequent itemsets.\n",
    "model.freqItemsets.sort(\"freq\", ascending=False).show(30, False)\n",
    "\n",
    "# Display generated association rules.\n",
    "model.associationRules.sort(\"confidence\", ascending=False).show(30, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
